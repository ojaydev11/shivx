"""
Neural Creative Problem Solver - Learned creativity using neural networks.

Replaces algorithmic creative solver with end-to-end learned model that:
- Learns creative patterns from data
- Generates novel solutions using neural networks
- Improves over time with experience

This is a key upgrade from heuristic to learned AI.
"""

import logging
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime

from core.ml.neural_base import BaseNeuralModel, ModelConfig

logger = logging.getLogger(__name__)


@dataclass
class CreativeSolution:
    """A creative solution generated by neural network"""
    id: str
    description: str
    embedding: np.ndarray  # Neural embedding
    novelty_score: float
    feasibility_score: float
    effectiveness_score: float
    generation_method: str = "neural"
    timestamp: datetime = field(default_factory=datetime.utcnow)

    def overall_score(self) -> float:
        """Compute overall solution quality"""
        return (
            0.3 * self.novelty_score +
            0.3 * self.feasibility_score +
            0.4 * self.effectiveness_score
        )


class CreativeTransformer(BaseNeuralModel):
    """
    Transformer-based creative problem solver

    Learns to generate creative solutions from problem descriptions
    """

    def __init__(self, config: ModelConfig):
        super().__init__(config)

        # Problem encoder
        self.problem_encoder = nn.Sequential(
            nn.Linear(config.input_dim, config.hidden_dims[0]),
            nn.ReLU(),
            nn.Dropout(config.dropout),
            nn.Linear(config.hidden_dims[0], config.hidden_dims[1]),
        )

        # Creative latent space
        self.latent_dim = 128
        self.to_latent = nn.Linear(config.hidden_dims[1], self.latent_dim)

        # Solution decoder
        self.solution_decoder = nn.Sequential(
            nn.Linear(self.latent_dim, config.hidden_dims[1]),
            nn.ReLU(),
            nn.Dropout(config.dropout),
            nn.Linear(config.hidden_dims[1], config.hidden_dims[0]),
            nn.ReLU(),
            nn.Linear(config.hidden_dims[0], config.output_dim),
        )

        # Novelty predictor
        self.novelty_head = nn.Sequential(
            nn.Linear(config.output_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

        # Feasibility predictor
        self.feasibility_head = nn.Sequential(
            nn.Linear(config.output_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

        logger.info(f"Creative Transformer: {self.count_parameters()} params")

    def forward(
        self,
        problem_embedding: torch.Tensor,
        temperature: float = 1.0
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Generate creative solution

        Args:
            problem_embedding: Embedding of problem (batch, input_dim)
            temperature: Sampling temperature for creativity (higher = more creative)

        Returns:
            (solution_embedding, novelty, feasibility)
        """
        # Encode problem
        encoded = self.problem_encoder(problem_embedding)

        # Map to creative latent space
        latent = self.to_latent(encoded)

        # Add creative noise (temperature-controlled)
        if self.training or temperature > 0:
            noise = torch.randn_like(latent) * temperature
            latent = latent + noise

        # Decode to solution
        solution = self.solution_decoder(latent)

        # Predict quality scores
        novelty = self.novelty_head(solution)
        feasibility = self.feasibility_head(solution)

        return solution, novelty, feasibility

    def generate_multiple_solutions(
        self,
        problem_embedding: torch.Tensor,
        num_solutions: int = 5,
        temperature: float = 1.0
    ) -> List[Tuple[torch.Tensor, float, float]]:
        """
        Generate multiple creative solutions

        Args:
            problem_embedding: Problem embedding
            num_solutions: Number of solutions to generate
            temperature: Creativity temperature

        Returns:
            List of (solution, novelty, feasibility)
        """
        solutions = []

        self.eval()
        with torch.no_grad():
            for _ in range(num_solutions):
                solution, novelty, feasibility = self.forward(
                    problem_embedding,
                    temperature=temperature
                )
                solutions.append((
                    solution[0],
                    novelty[0].item(),
                    feasibility[0].item()
                ))

        return solutions


class NeuralCreativeSolver:
    """
    Neural creative problem solver - learned creativity

    Learns to generate creative solutions from examples
    """

    def __init__(
        self,
        input_dim: int = 256,
        output_dim: int = 256,
        device: str = "cpu",
        temperature: float = 1.2
    ):
        """
        Initialize neural creative solver

        Args:
            input_dim: Problem embedding dimension
            output_dim: Solution embedding dimension
            device: Device to use
            temperature: Creativity temperature (higher = more creative)
        """
        self.device = device
        self.temperature = temperature

        # Create neural model
        config = ModelConfig(
            model_name="creative_transformer",
            input_dim=input_dim,
            hidden_dims=[512, 256],
            output_dim=output_dim,
            dropout=0.2,
            device=device
        )

        self.model = CreativeTransformer(config)
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)

        # Solution history for novelty calculation
        self.solution_history: List[np.ndarray] = []

        logger.info(f"Neural Creative Solver initialized: {temperature} temperature")

    def solve(
        self,
        problem: Dict[str, Any],
        num_solutions: int = 5,
    ) -> List[CreativeSolution]:
        """
        Generate creative solutions to a problem

        Args:
            problem: Problem specification with 'description' key
            num_solutions: Number of solutions to generate

        Returns:
            List of creative solutions
        """
        # Embed problem (simplified - in production use language model)
        problem_text = problem.get('description', '')
        problem_embedding = self._embed_problem(problem_text)

        # Generate solutions using neural network
        problem_tensor = torch.FloatTensor(problem_embedding).unsqueeze(0).to(self.device)

        solutions_data = self.model.generate_multiple_solutions(
            problem_tensor,
            num_solutions=num_solutions,
            temperature=self.temperature
        )

        # Convert to CreativeSolution objects
        solutions = []
        for i, (solution_tensor, novelty, feasibility) in enumerate(solutions_data):
            solution_embedding = solution_tensor.cpu().numpy()

            # Calculate effectiveness (simple heuristic for now)
            effectiveness = (novelty + feasibility) / 2.0

            # Calculate novelty relative to history
            if self.solution_history:
                relative_novelty = self._calculate_relative_novelty(solution_embedding)
                novelty = 0.7 * novelty + 0.3 * relative_novelty

            solution = CreativeSolution(
                id=f"neural_sol_{i}",
                description=f"Neural solution {i+1} for: {problem_text[:50]}...",
                embedding=solution_embedding,
                novelty_score=novelty,
                feasibility_score=feasibility,
                effectiveness_score=effectiveness,
                generation_method="neural_transformer"
            )

            solutions.append(solution)
            self.solution_history.append(solution_embedding)

        # Keep history limited
        if len(self.solution_history) > 1000:
            self.solution_history = self.solution_history[-1000:]

        logger.info(f"Generated {len(solutions)} neural creative solutions")

        return solutions

    def _embed_problem(self, text: str) -> np.ndarray:
        """
        Embed problem text (simplified version)

        In production, use a language model like BERT
        """
        # Simple hash-based embedding for demo
        # In production: use Sentence-BERT or similar
        np.random.seed(hash(text) % (2**32))
        embedding = np.random.randn(256)
        embedding = embedding / np.linalg.norm(embedding)

        return embedding

    def _calculate_relative_novelty(self, solution_embedding: np.ndarray) -> float:
        """
        Calculate novelty relative to solution history

        Returns:
            Novelty score (0-1)
        """
        if not self.solution_history:
            return 1.0

        # Calculate similarity to past solutions
        similarities = []
        for past_solution in self.solution_history[-100:]:  # Last 100
            similarity = np.dot(solution_embedding, past_solution)
            similarity = similarity / (
                np.linalg.norm(solution_embedding) * np.linalg.norm(past_solution) + 1e-8
            )
            similarities.append(similarity)

        # Novelty = 1 - max similarity
        max_similarity = np.max(similarities)
        novelty = 1.0 - max_similarity

        return max(0.0, min(1.0, novelty))

    def train_on_examples(
        self,
        problems: List[Dict[str, Any]],
        solutions: List[Dict[str, Any]],
        epochs: int = 50
    ):
        """
        Train creative solver on example problems and solutions

        Args:
            problems: List of problems
            solutions: List of solutions
            epochs: Training epochs
        """
        logger.info(f"Training neural creative solver on {len(problems)} examples")

        self.model.train()

        for epoch in range(epochs):
            total_loss = 0.0

            for problem, solution in zip(problems, solutions):
                # Embed problem and solution
                problem_emb = self._embed_problem(problem.get('description', ''))
                solution_emb = self._embed_problem(solution.get('description', ''))

                problem_tensor = torch.FloatTensor(problem_emb).unsqueeze(0).to(self.device)
                solution_tensor = torch.FloatTensor(solution_emb).unsqueeze(0).to(self.device)

                # Forward pass
                self.optimizer.zero_grad()
                pred_solution, pred_novelty, pred_feasibility = self.model(problem_tensor)

                # Loss: reconstruction + quality prediction
                recon_loss = F.mse_loss(pred_solution, solution_tensor)

                # Get target quality scores
                target_novelty = torch.FloatTensor([solution.get('novelty', 0.7)]).to(self.device)
                target_feasibility = torch.FloatTensor([solution.get('feasibility', 0.8)]).to(self.device)

                novelty_loss = F.binary_cross_entropy(pred_novelty[0], target_novelty)
                feasibility_loss = F.binary_cross_entropy(pred_feasibility[0], target_feasibility)

                loss = recon_loss + 0.5 * novelty_loss + 0.5 * feasibility_loss

                # Backward pass
                loss.backward()
                self.optimizer.step()

                total_loss += loss.item()

            if epoch % 10 == 0:
                logger.info(f"Epoch {epoch}/{epochs}, Loss: {total_loss:.4f}")

        logger.info("Neural creative solver training complete")

    def get_stats(self) -> Dict[str, Any]:
        """Get neural creative solver statistics"""
        return {
            "model_parameters": self.model.count_parameters(),
            "temperature": self.temperature,
            "solutions_generated": len(self.solution_history),
            "device": self.device
        }


# Convenience function
def neural_creative_solve(
    problem_description: str,
    num_solutions: int = 5,
    temperature: float = 1.2
) -> List[CreativeSolution]:
    """
    Quick neural creative problem solving

    Args:
        problem_description: Description of problem
        num_solutions: Number of solutions
        temperature: Creativity level

    Returns:
        List of creative solutions
    """
    solver = NeuralCreativeSolver(temperature=temperature)

    problem = {"description": problem_description}
    solutions = solver.solve(problem, num_solutions=num_solutions)

    return solutions
